{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial\n",
    "\n",
    "IFT6135 â€“ Representation Learning\n",
    "\n",
    "A Deep Learning Course, January 2019\n",
    "\n",
    "By Chin-Wei Huang \n",
    "\n",
    "(Adapted from Sandeep Subramanian's MILA welcome tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to the torch tensor library\n",
    "### Torch's numpy equivalent with GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  3.6893e+19,  0.0000e+00],\n",
       "        [ 3.6893e+19,  2.4074e-35,  1.4013e-45],\n",
       "        [ 3.4009e-35,  1.8367e-40,  2.0115e+18],\n",
       "        [ 4.5821e-41,  2.4258e-35,  1.4013e-45],\n",
       "        [-1.6533e-06,  2.5250e-29,  0.0000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1800,  0.8330, -0.6901],\n",
      "        [ 0.2890,  0.3168, -0.6920],\n",
      "        [-0.8239,  0.8455, -0.8767],\n",
      "        [ 0.8772,  0.5026,  0.1646],\n",
      "        [ 0.2608, -0.3901,  0.7063]])\n",
      "tensor([[ 0.6121, -0.7246, -0.9442],\n",
      "        [ 0.1773,  0.7809, -0.9708],\n",
      "        [-0.3570,  0.8262, -0.2329],\n",
      "        [-0.7994, -0.2972,  0.3238],\n",
      "        [-0.7662, -0.6796,  0.1692]])\n"
     ]
    }
   ],
   "source": [
    "# intialization\n",
    "print(torch.Tensor(5, 3).uniform_(-1, 1))\n",
    "# sampling\n",
    "print(torch.rand(5,3)*2-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get it's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3).uniform_(-1, 1)\n",
    "print(x.size())\n",
    "\n",
    "# or your favorite np_array.shape\n",
    "print(x.shape)\n",
    "\n",
    "# dimensionality of the 0'th axis?\n",
    "# print(???)\n",
    "print(x.size(0))\n",
    "print(x.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Types\n",
    "source: http://pytorch.org/docs/master/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Data type |Tensor|\n",
    "|----------|------|\n",
    "|32-bit floating point|\ttorch.FloatTensor|\n",
    "|64-bit floating point|\ttorch.DoubleTensor|\n",
    "|16-bit floating point|\ttorch.HalfTensor|\n",
    "|8-bit integer (unsigned)|torch.ByteTensor|\n",
    "|8-bit integer (signed)|torch.CharTensor|\n",
    "|16-bit integer (signed)|torch.ShortTensor|\n",
    "|32-bit integer (signed)|torch.IntTensor|\n",
    "|64-bit integer (signed)|torch.LongTensor|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation from lists & numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  2,   6],\n",
       "        [  4,  18]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.LongTensor([[1, 3], [2, 9]])\n",
    "print(z.type())\n",
    "# Cast to numpy ndarray\n",
    "print(z.numpy().dtype)\n",
    "z_ = torch.LongTensor([[1, 3], [2, 9]])\n",
    "z+z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor\n",
      "torch.FloatTensor\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Data type inferred from numpy\n",
    "print(torch.from_numpy(np.random.rand(5, 3)).type())\n",
    "print(torch.from_numpy(np.random.rand(5, 3).astype(np.float32)).type())\n",
    "print(torch.from_numpy(np.random.rand(5, 3)).float().dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9335,  1.7467,  0.1057],\n",
       "        [ 0.3516,  1.0909,  1.7426],\n",
       "        [ 0.6338,  1.2330,  1.6327],\n",
       "        [ 0.7595,  1.2103,  0.9412],\n",
       "        [ 1.2295,  1.0834,  1.3096]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examples of type error\n",
    "a = torch.randn(1) # x ~ N(0,1)\n",
    "b = torch.from_numpy(np.ones(1)).float()\n",
    "\n",
    "x+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9601,  1.6281,     nan],\n",
      "        [    nan,  0.4508,  1.0954],\n",
      "        [    nan,  5.1548,  1.1561],\n",
      "        [    nan,  0.3945,     nan],\n",
      "        [ 0.4676,  0.0382,  1.0491]])\n"
     ]
    }
   ],
   "source": [
    "y = x ** torch.randn(5, 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7650,  2.1209, -1.9414],\n",
      "        [-0.9739,  0.4886,  4.6878],\n",
      "        [-0.3125,  0.1874,  1.8736],\n",
      "        [-0.1248,  0.0709, -0.0995],\n",
      "        [ 0.1461,  0.0712,  0.3796]])\n",
      "tensor([[ 0.7650,  2.1209, -1.9414],\n",
      "        [-0.9739,  0.4886,  4.6878],\n",
      "        [-0.3125,  0.1874,  1.8736],\n",
      "        [-0.1248,  0.0709, -0.0995],\n",
      "        [ 0.1461,  0.0712,  0.3796]])\n"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(5, 3)\n",
    "y = x / torch.sqrt(noise ** 2)\n",
    "# equal to torch.abs\n",
    "y_ = x / torch.abs(noise)\n",
    "\n",
    "print(y)\n",
    "print(y_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[ 0.9335,  0.7467, -0.8943],\n",
      "        [-0.6484,  0.0909,  0.7426],\n",
      "        [-0.3662,  0.2330,  0.6327],\n",
      "        [-0.2405,  0.2103, -0.0588],\n",
      "        [ 0.2295,  0.0834,  0.3096]])\n",
      "tensor([[ 0.9335,  1.7467,  1.1057],\n",
      "        [-0.6484,  1.0909,  2.7426],\n",
      "        [-0.3662,  1.2330,  2.6327],\n",
      "        [-0.2405,  1.2103,  1.9412],\n",
      "        [ 0.2295,  1.0834,  2.3096]])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x)\n",
    "#y = x + torch.arange(5).view(5,1)\n",
    "y = x + torch.arange(3)\n",
    "print(y)\n",
    "# print(x + torch.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 15])\n",
      "torch.Size([50, 15])\n",
      "torch.Size([50, 1, 15])\n",
      "torch.Size([50, 15])\n",
      "\n",
      "torch.Size([10, 5, 15])\n",
      "torch.Size([5, 15, 10])\n",
      "torch.Size([10, 15, 5])\n",
      "torch.Size([10, 15, 5])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(5, 10, 15)\n",
    "print(y.size())\n",
    "print(y.view(-1, 15).size())  # Same as doing y.view(50, 15)\n",
    "print(y.view(-1, 15).unsqueeze(1).size()) # Adds a dimension at index 1.\n",
    "print(y.view(-1, 15).unsqueeze(1).unsqueeze(2).unsqueeze(3).squeeze().size())\n",
    "# If input is of shape: (Ax1xBxCx1xD)(Ax1xBxCx1xD) then the out Tensor will be of shape: (AxBxCxD)(AxBxCxD)\n",
    "print()\n",
    "print(y.transpose(0, 1).size())\n",
    "print(y.transpose(1, 2).size())\n",
    "print(y.transpose(0, 1).transpose(1, 2).size())\n",
    "print(y.permute(1, 2, 0).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100, 15])\n",
      "torch.Size([50, 100, 15])\n",
      "torch.Size([2500, 100, 15])\n"
     ]
    }
   ],
   "source": [
    "print(y.view(-1, 15).unsqueeze(1).expand(50, 100, 15).size())\n",
    "print(y.view(-1, 15).unsqueeze(1).expand_as(torch.randn(50, 100, 15)).size())\n",
    "# don't confuse it with tensor.repeat ...\n",
    "print(y.view(-1, 15).unsqueeze(1).repeat(50,100,1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 30])\n",
      "torch.Size([2, 5, 10, 15])\n",
      "torch.Size([2, 5, 10, 15])\n"
     ]
    }
   ],
   "source": [
    "# 2 is the dimension over which the tensors are concatenated\n",
    "print(torch.cat([y, y], 2).size())\n",
    "# stack concatenates the sequence of tensors along a new dimension.\n",
    "print(torch.stack([y, y], 0).size())\n",
    "\n",
    "# Q: how to do tensor.stack using cat?\n",
    "print(torch.cat([y[None], y[None]], 0).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 4])\n",
      "tensor([ 1,  0])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([3, 4])\n",
      "tensor([[  0.,   1.,   2.,   3.],\n",
      "        [  4.,   5.,   6.,   7.],\n",
      "        [  8.,   9.,  10.,  11.]])\n",
      "tensor([[ 1.],\n",
      "        [ 6.],\n",
      "        [ 8.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(2, 3, 4)\n",
    "print(y[[1, 0, 1, 1]].size())\n",
    "\n",
    "# PyTorch doesn't support negative strides yet so ::-1 does not work.\n",
    "rev_idx = torch.arange(1, -1, -1).long()\n",
    "print(rev_idx)\n",
    "print(y[rev_idx].size())\n",
    "\n",
    "\n",
    "# gather(input, dim, index)\n",
    "v = torch.arange(12).view(3,4)\n",
    "print(v.shape)\n",
    "print(v)\n",
    "# [0,1,2,3]\n",
    "# [4,5,6,7]\n",
    "# [8,9,10,11]\n",
    "# want to return [1,6,8]\n",
    "\n",
    "print(torch.gather(v, 1, torch.tensor([1,2,0]).long().unsqueeze(1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2456  1.1543  0.5376  0.4358 -0.0369\n",
       " 0.8247 -0.4143 -0.7188  0.3953  0.2573\n",
       "-0.1346  0.7329  0.5156  0.0864 -0.1349\n",
       "-0.3555  0.3135  0.3921 -0.1428 -0.1368\n",
       "-0.4385  0.5601  0.6533 -0.2793 -0.5220\n",
       "[torch.cuda.HalfTensor of size 5x5 (GPU 0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cuda.HalfTensor(5, 3).uniform_(-1, 1)\n",
    "y = torch.cuda.HalfTensor(3, 5).uniform_(-1, 1)\n",
    "torch.matmul(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move tensors on the CPU -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.3758 -0.1090  0.7911\n",
      " 0.2839 -0.9136  0.1070\n",
      " 0.9184  0.5113 -0.8040\n",
      "-0.3412 -0.8895 -0.5780\n",
      "-0.0992  0.0983  0.6074\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      "-0.3758 -0.1090  0.7911\n",
      " 0.2839 -0.9136  0.1070\n",
      " 0.9184  0.5113 -0.8040\n",
      "-0.3412 -0.8895 -0.5780\n",
      "-0.0992  0.0983  0.6074\n",
      "[torch.cuda.FloatTensor of size 5x3 (GPU 0)]\n",
      "\n",
      "\n",
      "-0.3758 -0.1090  0.7911\n",
      " 0.2839 -0.9136  0.1070\n",
      " 0.9184  0.5113 -0.8040\n",
      "-0.3412 -0.8895 -0.5780\n",
      "-0.0992  0.0983  0.6074\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n",
    "print(x)\n",
    "x = x.cuda(device=0)\n",
    "print(x)\n",
    "x = x.cpu()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Contiguity in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9361,  0.5925, -0.3561],\n",
      "        [-0.2556, -0.8500,  0.6730],\n",
      "        [ 0.8848, -0.4681,  0.7800],\n",
      "        [ 0.5135, -0.4303, -0.7775],\n",
      "        [ 0.0840, -0.3217, -0.7249]])\n",
      "tensor([[ 0.9361,  0.5925, -0.3561],\n",
      "        [-0.2556, -0.8500,  0.6730],\n",
      "        [ 0.8848, -0.4681,  0.7800],\n",
      "        [ 0.5135, -0.4303, -0.7775],\n",
      "        [ 0.0840, -0.3217, -0.7249]])\n",
      "Contiguity : True \n",
      "Contiguity : False \n",
      "Contiguity : True \n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n",
    "print(x)\n",
    "#x = x.cuda(device=0)\n",
    "print(x)\n",
    "print('Contiguity : %s ' % (x.is_contiguous()))\n",
    "x = x.unsqueeze(0).expand(30, 5, 3)\n",
    "print('Contiguity : %s ' % (x.is_contiguous()))\n",
    "x = x.contiguous()\n",
    "print('Contiguity : %s ' % (x.is_contiguous()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
